"""
Test: Distributed Docling Service Architecture

This test verifies the complete flow:
1. services.py uploads PDF to S3
2. services.py sends NATS message to docling worker  
3. Docling worker downloads from S3, processes with docling, responds
4. services.py receives response with actual docling results

This is the core distributed architecture we want.
"""
import pytest
import asyncio
import tempfile
import os
from pathlib import Path
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services import DocumentService

@pytest.fixture
def climate_pdf():
    """Create a realistic climate PDF for testing docling processing"""
    with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp:
        c = canvas.Canvas(tmp.name, pagesize=letter)
        
        # Create realistic climate content for docling to extract
        c.drawString(100, 750, "Climate Risk Assessment 2024")
        c.drawString(100, 720, "Executive Summary")
        c.drawString(100, 690, "")
        c.drawString(100, 660, "This report evaluates climate change impacts on our operations.")
        c.drawString(100, 630, "Key findings:")
        c.drawString(120, 600, "‚Ä¢ Global temperature increase of 1.5¬∞C by 2030")
        c.drawString(120, 570, "‚Ä¢ Sea level rise affecting coastal infrastructure")
        c.drawString(120, 540, "‚Ä¢ Increased extreme weather events")
        c.drawString(100, 510, "")
        c.drawString(100, 480, "Mitigation Strategies:")
        c.drawString(120, 450, "1. Carbon neutrality by 2050")
        c.drawString(120, 420, "2. Renewable energy transition")
        c.drawString(120, 390, "3. Climate adaptation measures")
        c.drawString(100, 360, "")
        c.drawString(100, 330, "Investment Required: $10M over 5 years")
        c.drawString(100, 300, "Expected ROI: 15% reduction in climate risks")
        
        c.save()
        
        yield Path(tmp.name)
        
        # Cleanup
        os.unlink(tmp.name)

@pytest.mark.asyncio
async def test_distributed_docling_service_end_to_end(climate_pdf):
    """
    Test the complete distributed docling service architecture
    
    This test verifies:
    1. ‚úÖ DocumentService uploads PDF to S3
    2. ‚úÖ DocumentService sends NATS message to docling worker
    3. ‚úÖ Docling worker downloads from S3 and processes with real docling
    4. ‚úÖ DocumentService receives actual docling results
    """
    print("\nüöÄ Testing Complete Distributed Docling Service Architecture")
    print("=" * 70)
    
    # Initialize DocumentService (our services.py)
    doc_service = DocumentService()
    await doc_service.setup()
    
    print("‚úÖ DocumentService connected to S3 + NATS")
    
    # Read the test PDF
    with open(climate_pdf, 'rb') as f:
        pdf_content = f.read()
    
    print(f"üìÑ Created test PDF: {len(pdf_content)} bytes")
    
    # Step 1: Upload PDF to S3 via DocumentService
    print("\n--- Step 1: Upload PDF to S3 ---")
    resource_id = "climate_assessment_2024_test"
    s3_key = await doc_service.store_document(pdf_content, resource_id)
    
    print(f"‚úÖ PDF uploaded to S3: {s3_key}")
    
    # Verify upload worked
    downloaded_content = await doc_service.get_document(s3_key)
    assert downloaded_content == pdf_content
    print(f"‚úÖ Verified S3 upload: {len(downloaded_content)} bytes retrieved")
    
    # Step 2 & 3 & 4: Send to docling worker and get results
    print("\n--- Step 2-4: Process via Docling Worker ---")
    print("üì§ Sending NATS message to docling worker...")
    print("‚è≥ Docling worker will: download from S3 ‚Üí process with docling ‚Üí respond")
    
    # This calls the distributed architecture:
    # - Sends NATS message to docling worker
    # - Docling worker downloads from S3, processes with docling
    # - Returns real docling results
    try:
        result = await doc_service.process_document(s3_key)
        
        print("‚úÖ Received response from docling worker!")
        
        # Verify we got a real docling response
        assert result["status"] == "success"
        assert "result" in result
        
        docling_result = result["result"]
        
        # Verify docling extracted actual content
        assert "text" in docling_result
        assert "markdown" in docling_result
        assert "metadata" in docling_result
        
        extracted_text = docling_result["text"]
        metadata = docling_result["metadata"]
        
        print(f"üìä Docling Results:")
        print(f"   ‚úÖ Extracted text: {len(extracted_text)} characters")
        print(f"   ‚úÖ Pages processed: {metadata.get('pages', 'unknown')}")
        print(f"   ‚úÖ Format: {metadata.get('format', 'unknown')}")
        print(f"   ‚úÖ Processed by: {metadata.get('processed_by', 'unknown')}")
        
        # Show sample of actual extracted content
        print(f"\nüìÑ REAL DOCLING EXTRACTED CONTENT (first 200 chars):")
        print("-" * 60)
        print(extracted_text[:200] + "..." if len(extracted_text) > 200 else extracted_text)
        print("-" * 60)
        
        # Verify content quality - should contain our test content
        assert len(extracted_text) > 100  # Should extract meaningful content
        assert "climate" in extracted_text.lower() or "Climate" in extracted_text
        
        print("‚úÖ Content quality verified - docling extracted meaningful text!")
        
    except asyncio.TimeoutError:
        print("‚ö†Ô∏è  Timeout - make sure docling worker is running!")
        print("   Run: python docling_worker.py")
        pytest.skip("Docling worker not available - run 'python docling_worker.py'")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        print("‚ö†Ô∏è  Make sure docling worker is running!")
        print("   Run: python docling_worker.py")
        raise
    
    # Cleanup
    await doc_service.delete_document(s3_key)
    await doc_service.close()
    
    print("\nüéâ Distributed Docling Service Test Completed Successfully!")
    print("\nüìã Verified Architecture Components:")
    print("   ‚úÖ services.py uploads PDF to S3")
    print("   ‚úÖ services.py sends NATS message to docling worker")
    print("   ‚úÖ Docling worker downloads from S3") 
    print("   ‚úÖ Docling worker processes with REAL docling")
    print("   ‚úÖ Docling worker responds with extracted content")
    print("   ‚úÖ services.py receives actual docling results")
    print("\nüöÄ Distributed architecture working perfectly!")
    print("   Replace HTTP API ‚úÖ")
    print("   S3 + NATS messaging ‚úÖ") 
    print("   Real docling processing ‚úÖ")

@pytest.mark.asyncio 
async def test_distributed_service_url_processing(climate_pdf):
    """Test processing a document from URL using the distributed architecture"""
    print("\nüåê Testing URL Processing via Distributed Architecture")
    
    # For this test, we'll simulate a URL by uploading first, then processing via URL method
    doc_service = DocumentService()
    await doc_service.setup()
    
    try:
        # This would normally download from a real URL
        # For testing, we pass the local file path (simulating URL download)
        resource_id = "url_test_document"
        
        # Note: In real usage, this would be:
        # result = await doc_service.process_url("https://example.com/document.pdf", resource_id)
        
        # For test, we'll use the store + process pattern to verify the flow
        with open(climate_pdf, 'rb') as f:
            content = f.read()
            
        s3_key = await doc_service.store_document(content, resource_id)
        result = await doc_service.process_document(s3_key)
        
        assert result["status"] == "success"
        print("‚úÖ URL processing flow verified via distributed architecture")
        
        # Cleanup
        await doc_service.delete_document(s3_key)
        
    except asyncio.TimeoutError:
        print("‚ö†Ô∏è  Docling worker not running - skipping URL test")
        pytest.skip("Docling worker not available")
    finally:
        await doc_service.close()


@pytest.mark.asyncio
async def test_docling_with_picture_descriptions_and_json():
    """
    Test Docling with VLM picture descriptions and structured JSON output
    
    This test verifies:
    1. ‚úÖ Processing real PDF with images (testpdf.pdf)
    2. ‚úÖ Docling VLM generates picture descriptions 
    3. ‚úÖ Structured JSON output includes image metadata
    4. ‚úÖ Picture descriptions are parsed and verified
    """
    print("\nüñºÔ∏è  Testing Docling VLM Picture Descriptions + JSON Output")
    print("=" * 65)
    
    # Use the user's testpdf.pdf file - try multiple locations
    possible_paths = [
        Path("../testpdf.pdf"),        # Parent directory 
        Path("testpdf.pdf"),           # Current directory
        Path("../../testpdf.pdf"),     # Up two levels
        Path("./testpdf.pdf"),         # Explicit current
    ]
    
    test_pdf_path = None
    for path in possible_paths:
        if path.exists():
            test_pdf_path = path
            break
    
    if test_pdf_path is None:
        print("‚ùå testpdf.pdf not found in any of these locations:")
        for path in possible_paths:
            print(f"   - {path.absolute()}")
        pytest.skip("testpdf.pdf not found - please ensure it's available")
        return
    
    print(f"üìÇ Found testpdf.pdf at: {test_pdf_path.absolute()}")
    
    # Initialize DocumentService
    doc_service = DocumentService()
    await doc_service.setup()
    
    print("‚úÖ DocumentService connected for VLM testing")
    
    # Read the test PDF
    with open(test_pdf_path, 'rb') as f:
        pdf_content = f.read()
    
    print(f"üìÑ Loaded testpdf.pdf: {len(pdf_content)} bytes")
    
    try:
        # Step 1: Upload PDF to S3
        print("\n--- Step 1: Upload PDF with Images to S3 ---")
        resource_id = "vlm_test_document"
        s3_key = await doc_service.store_document(pdf_content, resource_id)
        
        print(f"‚úÖ PDF uploaded to S3: {s3_key}")
        
        # Step 2: Process with VLM-enabled docling worker
        print("\n--- Step 2: Process with VLM Picture Descriptions ---")
        print("üì§ Sending NATS message for VLM processing...")
        print("ü§ñ Docling worker will: download ‚Üí process with VLM ‚Üí generate picture descriptions")

        # Configure VLM options for this request
        vlm_options = {
            "enabled": True,
            "model": "granite",  # Use Granite Vision (macOS 13.3 compatible)
            "prompt": "Describe this image in detail, including any text, objects, charts, tables, or diagrams you can see.",
            "images_scale": 2.0
        }

        print(f"üéØ VLM Configuration: {vlm_options}")

        # Process document with VLM options specified by publisher
        result = await doc_service.process_document(s3_key, vlm_options=vlm_options)
        
        assert result["status"] == "success"
        print("‚úÖ Received VLM processing response!")
        
        # Step 3: Verify and parse JSON structured data
        print("\n--- Step 3: Parse JSON Structured Data ---")
        
        docling_result = result["result"]
        structured_data = docling_result.get("structured_data")
        
        assert structured_data is not None, "Structured JSON data should be available"
        print(f"‚úÖ Got structured JSON data: {len(str(structured_data))} characters")
        
        # Step 4: Extract and verify picture descriptions
        print("\n--- Step 4: Extract Picture Descriptions ---")
        
        pictures_found = 0
        descriptions_found = 0
        
        # Parse the structured data for pictures/images
        if isinstance(structured_data, dict):
            # Look for pictures in the document structure
            if "pictures" in structured_data:
                pictures = structured_data["pictures"]
                pictures_found = len(pictures)
                print(f"üì∏ Found {pictures_found} pictures in document")
                
                for i, picture in enumerate(pictures):
                    print(f"\nüñºÔ∏è  Picture {i+1}:")
                    print(f"   üìç Reference: {picture.get('self_ref', 'N/A')}")
                    
                    # Look for annotations/descriptions
                    annotations = picture.get('annotations', {})
                    if annotations:
                        descriptions_found += 1
                        print(f"   ü§ñ VLM Description available!")
                        
                        # Print sample of description if available
                        for key, value in annotations.items():
                            if isinstance(value, str) and len(value) > 10:
                                preview = value[:100] + "..." if len(value) > 100 else value
                                print(f"   üìù {key}: {preview}")
                    else:
                        print(f"   ‚ö†Ô∏è  No VLM description found")
            
            # Also check for images in other parts of the structure
            if "images" in structured_data:
                images = structured_data["images"]
                print(f"üñºÔ∏è  Found {len(images)} additional images")
        
        # Step 5: Verify results
        print(f"\n--- Step 5: Verification Results ---")
        print(f"üìä Processing Results:")
        print(f"   ‚úÖ PDF processed successfully")
        print(f"   ‚úÖ Structured JSON generated: {bool(structured_data)}")
        print(f"   üì∏ Pictures found: {pictures_found}")
        print(f"   ü§ñ VLM descriptions generated: {descriptions_found}")
        print(f"   üìÑ Text extracted: {len(docling_result.get('text', ''))} characters")
        
        # Show sample of extracted text
        extracted_text = docling_result.get("text", "")
        if extracted_text:
            print(f"\nüìÑ EXTRACTED TEXT SAMPLE (first 200 chars):")
            print("-" * 50)
            print(extracted_text[:200] + "..." if len(extracted_text) > 200 else extracted_text)
            print("-" * 50)
        
        # Assertions for test validation
        assert len(extracted_text) > 0, "Should extract some text content"
        
        if pictures_found > 0:
            print(f"‚úÖ Document contains {pictures_found} pictures - VLM processing available")
            if descriptions_found > 0:
                print(f"üéâ VLM successfully generated {descriptions_found} picture descriptions!")
            else:
                print("‚ö†Ô∏è  Pictures found but no VLM descriptions - check VLM configuration")
        else:
            print("‚ÑπÔ∏è  No pictures detected in this PDF")
        
        # Save detailed results to files for examination
        import json
        from datetime import datetime
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = Path("docling_results")
        results_dir.mkdir(exist_ok=True)
        
        # Save structured JSON data
        if structured_data:
            json_file = results_dir / f"structured_data_{timestamp}.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(structured_data, f, indent=2, ensure_ascii=False)
            print(f"üíæ Saved structured JSON to: {json_file}")
        
        # Save extracted text
        text_file = results_dir / f"extracted_text_{timestamp}.md"
        with open(text_file, 'w', encoding='utf-8') as f:
            f.write(f"# Docling Extracted Text\n\n")
            f.write(f"**Processed:** {timestamp}\n")
            f.write(f"**Source:** testpdf.pdf\n")
            f.write(f"**Pictures found:** {pictures_found}\n\n")
            f.write("## Extracted Content\n\n")
            f.write(extracted_text)
        print(f"üìÑ Saved extracted text to: {text_file}")
        
        # Save picture analysis
        if pictures_found > 0:
            pictures_file = results_dir / f"pictures_analysis_{timestamp}.json"
            pictures_data = {
                "summary": {
                    "total_pictures": pictures_found,
                    "descriptions_generated": descriptions_found,
                    "processing_timestamp": timestamp
                },
                "pictures": structured_data.get("pictures", []) if structured_data else []
            }
            with open(pictures_file, 'w', encoding='utf-8') as f:
                json.dump(pictures_data, f, indent=2, ensure_ascii=False)
            print(f"üñºÔ∏è  Saved picture analysis to: {pictures_file}")
        
        # Create summary report
        summary_file = results_dir / f"summary_report_{timestamp}.md"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"# Docling Processing Summary Report\n\n")
            f.write(f"**Generated:** {timestamp}\n")
            f.write(f"**Source File:** testpdf.pdf ({len(pdf_content)} bytes)\n\n")
            f.write(f"## Processing Results\n\n")
            f.write(f"- ‚úÖ PDF processed successfully\n")
            f.write(f"- ‚úÖ Structured JSON generated: {bool(structured_data)}\n")
            f.write(f"- üì∏ Pictures found: **{pictures_found}**\n")
            f.write(f"- ü§ñ VLM descriptions generated: **{descriptions_found}**\n")
            f.write(f"- üìÑ Text extracted: **{len(extracted_text)} characters**\n")
            f.write(f"- üóÇÔ∏è JSON data size: **{len(str(structured_data))} characters**\n\n")
            if pictures_found > 0:
                f.write(f"## Picture Details\n\n")
                for i in range(pictures_found):
                    f.write(f"- Picture {i+1}: Detected in JSON structure\n")
            f.write(f"\n## Files Generated\n\n")
            f.write(f"- `{json_file.name}` - Full structured JSON data\n")
            f.write(f"- `{text_file.name}` - Extracted text content\n")
            if pictures_found > 0:
                f.write(f"- `{pictures_file.name}` - Picture analysis\n")
            f.write(f"- `{summary_file.name}` - This summary report\n")
        
        print(f"üìä Saved summary report to: {summary_file}")
        print(f"\nüìÅ All results saved in: {results_dir.absolute()}")
        
        # Cleanup
        await doc_service.delete_document(s3_key)
        
        print(f"\nüéâ VLM Picture Description Test Completed!")
        print(f"\nüìã Verified VLM Components:")
        print(f"   ‚úÖ PDF upload and processing")
        print(f"   ‚úÖ Docling VLM integration")
        print(f"   ‚úÖ Structured JSON output")
        print(f"   ‚úÖ Picture detection: {pictures_found} images")
        print(f"   ‚úÖ VLM descriptions: {descriptions_found} generated")
        print(f"\nüîç Examine detailed results in: {results_dir.absolute()}")
        
    except asyncio.TimeoutError:
        print("‚ö†Ô∏è  Timeout - make sure docling worker with VLM is running!")
        pytest.skip("Docling worker not available")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        raise
    finally:
        await doc_service.close() 